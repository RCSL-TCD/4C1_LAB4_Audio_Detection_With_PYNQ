{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9571f04e",
   "metadata": {},
   "source": [
    "# Lab5 B: Generate your QNN to hardware \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d76cf",
   "metadata": {},
   "source": [
    "In Lab5 A, we trained a quantised network, and in this lab we will compile it to a hardware format to deploy it on our FPGAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828ce373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from brevitas.nn import QuantConv2d, QuantLinear, QuantReLU \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3b445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\".\")  # replace with your root path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a623a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantMLPKWS_Dropout(nn.Module):\n",
    "    def __init__(self, num_classes=12, hidden_dim=256, dropout_p=0.2, w_bit=3, a_bit=3):\n",
    "        super().__init__()\n",
    "        self.in_features = 1 * 10 * 49\n",
    "\n",
    "        # Layer 1: 490 -> 256\n",
    "        self.fc1 = QuantLinear(\n",
    "            in_features=self.in_features,\n",
    "            out_features=hidden_dim,\n",
    "            weight_bit_width=w_bit,   # W3\n",
    "            bias=True,\n",
    "            return_quant_tensor=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.act1 = QuantReLU(\n",
    "            bit_width=a_bit,          # A3\n",
    "            return_quant_tensor=False\n",
    "        )\n",
    "        self.drop1 = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        # Layer 2: 256 -> 256\n",
    "        self.fc2 = QuantLinear(\n",
    "            in_features=hidden_dim,\n",
    "            out_features=hidden_dim,\n",
    "            weight_bit_width=w_bit,\n",
    "            bias=True,\n",
    "            return_quant_tensor=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.act2 = QuantReLU(\n",
    "            bit_width=a_bit,\n",
    "            return_quant_tensor=False\n",
    "        )\n",
    "        self.drop2 = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        # Layer 3: 256 -> 256\n",
    "        self.fc3 = QuantLinear(\n",
    "            in_features=hidden_dim,\n",
    "            out_features=hidden_dim,\n",
    "            weight_bit_width=w_bit,\n",
    "            bias=True,\n",
    "            return_quant_tensor=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.act3 = QuantReLU(\n",
    "            bit_width=a_bit,\n",
    "            return_quant_tensor=False\n",
    "        )\n",
    "        self.drop3 = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        # Output layer: 256 -> num_classes\n",
    "        self.fc_out = QuantLinear(\n",
    "            in_features=hidden_dim,\n",
    "            out_features=num_classes,\n",
    "            weight_bit_width=w_bit,\n",
    "            bias=True,\n",
    "            return_quant_tensor=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, 10, 49) -> flatten -> (B, 490)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.drop3(x)\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8436a288",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxscript'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m export_path = \u001b[38;5;28mstr\u001b[39m(root_path / \u001b[33m\"\u001b[39m\u001b[33mexports\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mkws_mlp_w3a3_qonnx.onnx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mexport_qonnx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# sometimes use input_t=dummy_input depending on brevitas version\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_path\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQONNX model successfully exported to:\u001b[39m\u001b[33m\"\u001b[39m, export_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lab5/lib/python3.12/site-packages/brevitas/export/__init__.py:19\u001b[39m, in \u001b[36mexport_qonnx\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(QONNXManager.export)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexport_qonnx\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQONNXManager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lab5/lib/python3.12/site-packages/brevitas/export/onnx/manager.py:198\u001b[39m, in \u001b[36mONNXBaseManager.export\u001b[39m\u001b[34m(cls, module, args, export_path, input_shape, input_t, disable_warnings, **onnx_export_kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexport\u001b[39m(\n\u001b[32m    189\u001b[39m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m         disable_warnings=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    197\u001b[39m         **onnx_export_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexport_onnx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_warnings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43monnx_export_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lab5/lib/python3.12/site-packages/brevitas/export/onnx/manager.py:169\u001b[39m, in \u001b[36mONNXBaseManager.export_onnx\u001b[39m\u001b[34m(cls, module, args, export_path, input_shape, input_t, disable_warnings, **onnx_export_kwargs)\u001b[39m\n\u001b[32m    166\u001b[39m     export_target = model_bytes\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m PatchFp8Ops():\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43monnx_export_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# restore the model to previous properties\u001b[39;00m\n\u001b[32m    172\u001b[39m module.apply(\u001b[38;5;28;01mlambda\u001b[39;00m m: _restore_act_caching_mode(m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lab5/lib/python3.12/site-packages/torch/onnx/__init__.py:282\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03mSetting ``dynamo=True`` enables the new ONNX export logic\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m    *dynamo* is now True by default.\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dynamo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, torch.export.ExportedProgram):\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _compat\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, torch.Tensor):\n\u001b[32m    285\u001b[39m         args = (args,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lab5/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_compat.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _constants \u001b[38;5;28;01mas\u001b[39;00m onnx_constants\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_import\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m onnx, onnxscript_apis, onnxscript_ir \u001b[38;5;28;01mas\u001b[39;00m ir\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _constants,\n\u001b[32m     18\u001b[39m     _core,\n\u001b[32m     19\u001b[39m     _dynamic_shapes,\n\u001b[32m     20\u001b[39m     _onnx_program,\n\u001b[32m     21\u001b[39m     _registration,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lab5/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mapping, Sequence\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Literal\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluator\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ir\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'onnxscript'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from brevitas.export import export_qonnx \n",
    "\n",
    "model = QuantMLPKWS_Dropout(\n",
    "    num_classes=12,\n",
    "    hidden_dim=256,\n",
    "    dropout_p=0.3,\n",
    "    w_bit=3,\n",
    "    a_bit=3\n",
    ").cpu()\n",
    "\n",
    "# --- 1. Load trained weights ---\n",
    "weight_dir = root_path / \"weights\"\n",
    "state_dict = torch.load(weight_dir / \"mlpw2a2_model_weights.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()  # Always switch to eval mode before export\n",
    "\n",
    "# --- 2. Prepare dummy input ---\n",
    "# The dummy input shape must match the modelâ€™s expected input (B, 1, 10, 49)\n",
    "dummy_input = torch.randn(1, 1, 10, 49)\n",
    "\n",
    "# --- 3. Export to QONNX (for FINN / FPGA deployment) ---\n",
    "export_path = str(root_path / \"exports\" / \"kws_mlp_w3a3_qonnx.onnx\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    export_qonnx(\n",
    "        model,\n",
    "        args=dummy_input,  # sometimes use input_t=dummy_input depending on brevitas version\n",
    "        export_path=export_path\n",
    "    )\n",
    "\n",
    "print(\"QONNX model successfully exported to:\", export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06493cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "ready_model_filename = model_dir + \"/mlp-ready.onnx\"\n",
    "input_shape = (1, 600)\n",
    "\n",
    "# create a dummy input tensor for the export\n",
    "input_a = np.random.randint(0, 1, size=input_shape).astype(np.float32)\n",
    "input_a = 2 * input_a - 1\n",
    "scale = 1.0\n",
    "input_t = torch.from_numpy(input_a * scale)\n",
    "\n",
    "#Move to CPU before export\n",
    "model_for_export.cpu()\n",
    "\n",
    "# Export to ONNX\n",
    "export_qonnx(\n",
    "    model_for_export, export_path=ready_model_filename, input_t=input_t\n",
    ")\n",
    "\n",
    "# clean-up\n",
    "qonnx_cleanup(ready_model_filename, out_file=ready_model_filename)\n",
    "\n",
    "# Setting the input datatype explicitly because it doesn't get derived from the export function\n",
    "model = ModelWrapper(ready_model_filename)\n",
    "model.set_tensor_datatype(model.graph.input[0].name, DataType[\"BIPOLAR\"])\n",
    "model.save(ready_model_filename)\n",
    "\n",
    "print(\"Model saved to %s\" % ready_model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
